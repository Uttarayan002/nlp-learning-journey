# -*- coding: utf-8 -*-
"""1. Text_Classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cvMH-BOEs22jfs8pzAZdwPSc344gjkqF

# Build a Spam vs. Ham Classifier
"""

import pandas as pd

# Load dataset
df = pd.read_csv("https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv", sep='\t', header=None, names=['label', 'message'])

# Quick look
df.head()

import string
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab')

stop_words = set(stopwords.words("english"))
lemmatizer = WordNetLemmatizer()

def clean_text(text):
  text = text.lower()
  text = ''.join([c for c in text if c not in string.punctuation])
  token = word_tokenize(text)
  token = [lemmatizer.lemmatize(w) for w in token if w not in stop_words]
  return ''.join(token)

df['cleaned'] = df['message'].apply(clean_text)

df

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer()
X = tfidf.fit_transform(df['cleaned'])

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Encode label
df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})

# Split
X_train, X_test, y_train, y_test = train_test_split(X, df['label_num'], test_size=0.2, random_state=42)

# Train
model = LogisticRegression()
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

model.predict(tfidf.transform(["Congratulations! You won a free cruise. Call now!"]))

